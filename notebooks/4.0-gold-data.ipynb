{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Medical Image - TFM\n",
    "<h4>subtitle: Generación de una tubería distribuida para la extracción de características en imágenes médicas patológicas</h4>\n",
    "license: European Union Public Licence (EUPL) v1.2\n",
    "\n",
    "<table>\n",
    "  <tr> <td> author name: </td> <td> Israel Llorens </td> </tr>\n",
    "  <tr> <td> email: </td> <td> sanchezis@hotmail.com </td> </tr>\n",
    "</table>\n",
    "\n",
    "<h7>date: 2025/03/23</h7>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inicialización"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/03/24 11:22:55 WARN Utils: Your hostname, Airon.local resolves to a loopback address: 127.0.0.1; using 192.168.100.210 instead (on interface en0)\n",
      "25/03/24 11:22:55 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/03/24 11:22:55 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "25/03/24 11:22:56 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n",
      "25/03/24 11:22:56 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.\n",
      "25/03/24 11:22:56 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.\n",
      "25/03/24 11:22:56 INFO SharedState: Warehouse path is 'file:/Users/illorens/Projects/source/Universidad/viu-MU-BD-and-DS-Image-Pathology/notebooks/spark-warehouse'.\n"
     ]
    }
   ],
   "source": [
    "import init\n",
    "from digital_pathology.spark import spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/03/24 11:52:56 INFO BlockManagerInfo: Removed broadcast_3_piece0 on 192.168.100.210:57096 in memory (size: 6.6 KiB, free: 9.4 GiB)\n",
      "25/03/24 11:52:56 INFO BlockManagerInfo: Removed broadcast_1_piece0 on 192.168.100.210:57096 in memory (size: 6.6 KiB, free: 9.4 GiB)\n",
      "25/03/24 11:52:56 INFO BlockManagerInfo: Removed broadcast_0_piece0 on 192.168.100.210:57096 in memory (size: 6.6 KiB, free: 9.4 GiB)\n",
      "25/03/24 11:52:56 INFO BlockManagerInfo: Removed broadcast_5_piece0 on 192.168.100.210:57096 in memory (size: 6.6 KiB, free: 9.4 GiB)\n",
      "25/03/24 11:52:56 INFO BlockManagerInfo: Removed broadcast_2_piece0 on 192.168.100.210:57096 in memory (size: 6.6 KiB, free: 9.4 GiB)\n",
      "25/03/24 11:52:56 INFO BlockManagerInfo: Removed broadcast_4_piece0 on 192.168.100.210:57096 in memory (size: 6.6 KiB, free: 9.4 GiB)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "try:\n",
    "    import pyspark\n",
    "    from pyspark.sql.functions import col, isnan, when, count,to_date,year,month,expr,hour,dayofweek,lower,array_remove,collect_list,lit\n",
    "    from pyspark.sql.functions import pandas_udf,split\n",
    "    from pyspark.sql.types import StructField,StructType,StringType,DoubleType,FloatType,IntegerType, ArrayType, DoubleType, LongType\n",
    "    import pyspark.sql.functions as F\n",
    "except:\n",
    "    pass\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "|2025-03-24|14:16:14.191| [WARNING] /Users/illorens/Projects/source/Universidad/viu-MU-BD-and-DS-Image-Pathology/.venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "\n",
      "|2025-03-24|14:16:18.578| [WARNING] /Users/illorens/Projects/source/Universidad/viu-MU-BD-and-DS-Image-Pathology/.venv/lib/python3.11/site-packages/albumentations/__init__.py:24: UserWarning: A new version of Albumentations is available: 2.0.5 (you have 1.4.21). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.\n",
      "  check_for_updates()\n",
      "\n",
      "INFO:root:****************************CREATING SPARK CLUSTER*******************************\n",
      "25/03/24 14:16:19 WARN Utils: Your hostname, Airon.local resolves to a loopback address: 127.0.0.1; using 192.168.100.210 instead (on interface en0)\n",
      "25/03/24 14:16:19 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/03/24 14:16:19 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "25/03/24 14:16:20 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n",
      "25/03/24 14:16:20 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.\n",
      "25/03/24 14:16:20 INFO SharedState: Warehouse path is 'file:/Users/illorens/Projects/source/Universidad/viu-MU-BD-and-DS-Image-Pathology/notebooks/spark-warehouse'.\n"
     ]
    }
   ],
   "source": [
    "# Copyright (c) 2024 Israel Llorens\n",
    "# Licensed under the EUPL-1.2  \n",
    "\n",
    "__author__ = \"Israel Llorens <sanchezis@hotmail.com>\"\n",
    "__copyright__ = \"Copyright 2024, Israel Llorens\"\n",
    "__license__ = \"EUPL-1.2\"\n",
    "\n",
    "import logging\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import glob\n",
    "import pyspark.sql.functions as F\n",
    "import pyspark.sql.types as T\n",
    "\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import BooleanType\n",
    "\n",
    "from tiatoolbox import logger\n",
    "from tiatoolbox.models.architecture.unet import UNetModel\n",
    "from tiatoolbox.models.engine.semantic_segmentor import (\n",
    "    IOSegmentorConfig,\n",
    "    SemanticSegmentor,\n",
    ")\n",
    "from tiatoolbox.utils.misc import download_data, imread\n",
    "from tiatoolbox.utils.visualization import overlay_prediction_mask\n",
    "from tiatoolbox.wsicore.wsireader import WSIReader\n",
    "\n",
    "try:\n",
    "    import pyspark\n",
    "    from pyspark.sql.functions import col, isnan, when, count,to_date,year,month,expr,hour,dayofweek,lower,array_remove,collect_list,lit\n",
    "    from pyspark.sql.functions import pandas_udf,split\n",
    "    from pyspark.sql.types import ArrayType, DoubleType, StringType\n",
    "    from pyspark.sql.types import StructField,StructType,StringType,DoubleType,FloatType,IntegerType, LongType\n",
    "    import pyspark.sql.functions as F\n",
    "except:\n",
    "    pass\n",
    "\n",
    "\n",
    "# Clear logger to use tiatoolbox.logger\n",
    "import logging\n",
    "import warnings\n",
    "\n",
    "if logging.getLogger().hasHandlers():\n",
    "    logging.getLogger().handlers.clear()\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "from matplotlib import cm\n",
    "\n",
    "from tiatoolbox import logger\n",
    "from tiatoolbox.models.architecture.unet import UNetModel\n",
    "from tiatoolbox.models.engine.semantic_segmentor import (\n",
    "    IOSegmentorConfig,\n",
    "    SemanticSegmentor,\n",
    ")\n",
    "from tiatoolbox.utils.misc import download_data, imread\n",
    "from tiatoolbox.utils.visualization import overlay_prediction_mask\n",
    "from tiatoolbox.wsicore.wsireader import WSIReader\n",
    "\n",
    "from urllib import request\n",
    "import certifi\n",
    "import ssl\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import histomicstk as htk\n",
    "import skimage\n",
    "import scipy as sp\n",
    "\n",
    "import init\n",
    "from digital_pathology.spark import spark\n",
    "from digital_pathology.process.model_selection import ResNetModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gold Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../data/3-nucleotids.parquet',\n",
       " '../data/2-stardist-nucleotids.parquet',\n",
       " '../data/0-extract.parquet',\n",
       " '../data/1-download.parquet',\n",
       " '../data/4-nucleotids.parquet']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glob.glob(os.path.join('..','data', '*.parquet') )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/03/24 14:20:21 INFO InMemoryFileIndex: It took 3 ms to list leaf files for 1 paths.\n",
      "25/03/24 14:20:21 INFO SparkContext: Starting job: parquet at NativeMethodAccessorImpl.java:0\n",
      "25/03/24 14:20:21 INFO DAGScheduler: Got job 4 (parquet at NativeMethodAccessorImpl.java:0) with 1 output partitions\n",
      "25/03/24 14:20:21 INFO DAGScheduler: Final stage: ResultStage 4 (parquet at NativeMethodAccessorImpl.java:0)\n",
      "25/03/24 14:20:21 INFO DAGScheduler: Parents of final stage: List()\n",
      "25/03/24 14:20:21 INFO DAGScheduler: Missing parents: List()\n",
      "25/03/24 14:20:21 INFO DAGScheduler: Submitting ResultStage 4 (MapPartitionsRDD[13] at parquet at NativeMethodAccessorImpl.java:0), which has no missing parents\n",
      "25/03/24 14:20:21 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 106.2 KiB, free 9.4 GiB)\n",
      "25/03/24 14:20:21 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 38.5 KiB, free 9.4 GiB)\n",
      "25/03/24 14:20:21 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 192.168.100.210:61924 (size: 38.5 KiB, free: 9.4 GiB)\n",
      "25/03/24 14:20:21 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:1540\n",
      "25/03/24 14:20:21 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 4 (MapPartitionsRDD[13] at parquet at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))\n",
      "25/03/24 14:20:21 INFO TaskSchedulerImpl: Adding task set 4.0 with 1 tasks resource profile 0\n",
      "25/03/24 14:20:21 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 4) (192.168.100.210, executor driver, partition 0, PROCESS_LOCAL, 9152 bytes) \n",
      "25/03/24 14:20:21 INFO Executor: Running task 0.0 in stage 4.0 (TID 4)\n",
      "25/03/24 14:20:21 INFO Executor: Finished task 0.0 in stage 4.0 (TID 4). 2026 bytes result sent to driver\n",
      "25/03/24 14:20:21 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 4) in 8 ms on 192.168.100.210 (executor driver) (1/1)\n",
      "25/03/24 14:20:21 INFO TaskSchedulerImpl: Removed TaskSet 4.0, whose tasks have all completed, from pool \n",
      "25/03/24 14:20:21 INFO DAGScheduler: ResultStage 4 (parquet at NativeMethodAccessorImpl.java:0) finished in 0,014 s\n",
      "25/03/24 14:20:21 INFO DAGScheduler: Job 4 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "25/03/24 14:20:21 INFO TaskSchedulerImpl: Killing all running tasks in stage 4: Stage finished\n",
      "25/03/24 14:20:21 INFO DAGScheduler: Job 4 finished: parquet at NativeMethodAccessorImpl.java:0, took 0,016020 s\n",
      "25/03/24 14:20:21 INFO InMemoryFileIndex: It took 28 ms to list leaf files for 1 paths.\n",
      "25/03/24 14:20:21 INFO SparkContext: Starting job: parquet at NativeMethodAccessorImpl.java:0\n",
      "25/03/24 14:20:21 INFO DAGScheduler: Got job 5 (parquet at NativeMethodAccessorImpl.java:0) with 1 output partitions\n",
      "25/03/24 14:20:21 INFO DAGScheduler: Final stage: ResultStage 5 (parquet at NativeMethodAccessorImpl.java:0)\n",
      "25/03/24 14:20:21 INFO DAGScheduler: Parents of final stage: List()\n",
      "25/03/24 14:20:21 INFO DAGScheduler: Missing parents: List()\n",
      "25/03/24 14:20:21 INFO DAGScheduler: Submitting ResultStage 5 (MapPartitionsRDD[15] at parquet at NativeMethodAccessorImpl.java:0), which has no missing parents\n",
      "25/03/24 14:20:21 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 106.2 KiB, free 9.4 GiB)\n",
      "25/03/24 14:20:21 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 38.5 KiB, free 9.4 GiB)\n",
      "25/03/24 14:20:21 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 192.168.100.210:61924 (size: 38.5 KiB, free: 9.4 GiB)\n",
      "25/03/24 14:20:21 INFO SparkContext: Created broadcast 7 from broadcast at DAGScheduler.scala:1540\n",
      "25/03/24 14:20:21 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 5 (MapPartitionsRDD[15] at parquet at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))\n",
      "25/03/24 14:20:21 INFO TaskSchedulerImpl: Adding task set 5.0 with 1 tasks resource profile 0\n",
      "25/03/24 14:20:21 INFO TaskSetManager: Starting task 0.0 in stage 5.0 (TID 5) (192.168.100.210, executor driver, partition 0, PROCESS_LOCAL, 9153 bytes) \n",
      "25/03/24 14:20:21 INFO Executor: Running task 0.0 in stage 5.0 (TID 5)\n",
      "25/03/24 14:20:21 INFO Executor: Finished task 0.0 in stage 5.0 (TID 5). 2202 bytes result sent to driver\n",
      "25/03/24 14:20:21 INFO TaskSetManager: Finished task 0.0 in stage 5.0 (TID 5) in 8 ms on 192.168.100.210 (executor driver) (1/1)\n",
      "25/03/24 14:20:21 INFO TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool \n",
      "25/03/24 14:20:21 INFO DAGScheduler: ResultStage 5 (parquet at NativeMethodAccessorImpl.java:0) finished in 0,021 s\n",
      "25/03/24 14:20:21 INFO DAGScheduler: Job 5 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "25/03/24 14:20:21 INFO TaskSchedulerImpl: Killing all running tasks in stage 5: Stage finished\n",
      "25/03/24 14:20:21 INFO DAGScheduler: Job 5 finished: parquet at NativeMethodAccessorImpl.java:0, took 0,022906 s\n",
      "25/03/24 14:20:21 INFO InMemoryFileIndex: It took 0 ms to list leaf files for 1 paths.\n",
      "25/03/24 14:20:21 INFO SparkContext: Starting job: parquet at NativeMethodAccessorImpl.java:0\n",
      "25/03/24 14:20:21 INFO DAGScheduler: Got job 6 (parquet at NativeMethodAccessorImpl.java:0) with 1 output partitions\n",
      "25/03/24 14:20:21 INFO DAGScheduler: Final stage: ResultStage 6 (parquet at NativeMethodAccessorImpl.java:0)\n",
      "25/03/24 14:20:21 INFO DAGScheduler: Parents of final stage: List()\n",
      "25/03/24 14:20:21 INFO DAGScheduler: Missing parents: List()\n",
      "25/03/24 14:20:21 INFO DAGScheduler: Submitting ResultStage 6 (MapPartitionsRDD[17] at parquet at NativeMethodAccessorImpl.java:0), which has no missing parents\n",
      "25/03/24 14:20:21 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 106.2 KiB, free 9.4 GiB)\n",
      "25/03/24 14:20:21 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 38.5 KiB, free 9.4 GiB)\n",
      "25/03/24 14:20:21 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 192.168.100.210:61924 (size: 38.5 KiB, free: 9.4 GiB)\n",
      "25/03/24 14:20:21 INFO SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:1540\n",
      "25/03/24 14:20:21 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 6 (MapPartitionsRDD[17] at parquet at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))\n",
      "25/03/24 14:20:21 INFO TaskSchedulerImpl: Adding task set 6.0 with 1 tasks resource profile 0\n",
      "25/03/24 14:20:21 INFO TaskSetManager: Starting task 0.0 in stage 6.0 (TID 6) (192.168.100.210, executor driver, partition 0, PROCESS_LOCAL, 9164 bytes) \n",
      "25/03/24 14:20:21 INFO Executor: Running task 0.0 in stage 6.0 (TID 6)\n",
      "25/03/24 14:20:21 INFO Executor: Finished task 0.0 in stage 6.0 (TID 6). 2308 bytes result sent to driver\n",
      "25/03/24 14:20:21 INFO TaskSetManager: Finished task 0.0 in stage 6.0 (TID 6) in 7 ms on 192.168.100.210 (executor driver) (1/1)\n",
      "25/03/24 14:20:21 INFO TaskSchedulerImpl: Removed TaskSet 6.0, whose tasks have all completed, from pool \n",
      "25/03/24 14:20:21 INFO DAGScheduler: ResultStage 6 (parquet at NativeMethodAccessorImpl.java:0) finished in 0,013 s\n",
      "25/03/24 14:20:21 INFO DAGScheduler: Job 6 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "25/03/24 14:20:21 INFO TaskSchedulerImpl: Killing all running tasks in stage 6: Stage finished\n",
      "25/03/24 14:20:21 INFO DAGScheduler: Job 6 finished: parquet at NativeMethodAccessorImpl.java:0, took 0,013643 s\n",
      "25/03/24 14:20:21 INFO InMemoryFileIndex: It took 0 ms to list leaf files for 1 paths.\n",
      "25/03/24 14:20:21 INFO SparkContext: Starting job: parquet at NativeMethodAccessorImpl.java:0\n",
      "25/03/24 14:20:21 INFO DAGScheduler: Got job 7 (parquet at NativeMethodAccessorImpl.java:0) with 1 output partitions\n",
      "25/03/24 14:20:21 INFO DAGScheduler: Final stage: ResultStage 7 (parquet at NativeMethodAccessorImpl.java:0)\n",
      "25/03/24 14:20:21 INFO DAGScheduler: Parents of final stage: List()\n",
      "25/03/24 14:20:21 INFO DAGScheduler: Missing parents: List()\n",
      "25/03/24 14:20:21 INFO DAGScheduler: Submitting ResultStage 7 (MapPartitionsRDD[19] at parquet at NativeMethodAccessorImpl.java:0), which has no missing parents\n",
      "25/03/24 14:20:21 INFO MemoryStore: Block broadcast_9 stored as values in memory (estimated size 106.2 KiB, free 9.4 GiB)\n",
      "25/03/24 14:20:21 INFO MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 38.5 KiB, free 9.4 GiB)\n",
      "25/03/24 14:20:21 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on 192.168.100.210:61924 (size: 38.5 KiB, free: 9.4 GiB)\n",
      "25/03/24 14:20:21 INFO SparkContext: Created broadcast 9 from broadcast at DAGScheduler.scala:1540\n",
      "25/03/24 14:20:21 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 7 (MapPartitionsRDD[19] at parquet at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))\n",
      "25/03/24 14:20:21 INFO TaskSchedulerImpl: Adding task set 7.0 with 1 tasks resource profile 0\n",
      "25/03/24 14:20:21 INFO TaskSetManager: Starting task 0.0 in stage 7.0 (TID 7) (192.168.100.210, executor driver, partition 0, PROCESS_LOCAL, 9155 bytes) \n",
      "25/03/24 14:20:21 INFO Executor: Running task 0.0 in stage 7.0 (TID 7)\n",
      "25/03/24 14:20:21 INFO Executor: Finished task 0.0 in stage 7.0 (TID 7). 2249 bytes result sent to driver\n",
      "25/03/24 14:20:21 INFO TaskSetManager: Finished task 0.0 in stage 7.0 (TID 7) in 7 ms on 192.168.100.210 (executor driver) (1/1)\n",
      "25/03/24 14:20:21 INFO TaskSchedulerImpl: Removed TaskSet 7.0, whose tasks have all completed, from pool \n",
      "25/03/24 14:20:21 INFO DAGScheduler: ResultStage 7 (parquet at NativeMethodAccessorImpl.java:0) finished in 0,016 s\n",
      "25/03/24 14:20:21 INFO DAGScheduler: Job 7 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "25/03/24 14:20:21 INFO TaskSchedulerImpl: Killing all running tasks in stage 7: Stage finished\n",
      "25/03/24 14:20:21 INFO DAGScheduler: Job 7 finished: parquet at NativeMethodAccessorImpl.java:0, took 0,016617 s\n",
      "25/03/24 14:20:21 INFO InMemoryFileIndex: It took 0 ms to list leaf files for 1 paths.\n",
      "25/03/24 14:20:21 INFO SparkContext: Starting job: parquet at NativeMethodAccessorImpl.java:0\n",
      "25/03/24 14:20:21 INFO DAGScheduler: Got job 8 (parquet at NativeMethodAccessorImpl.java:0) with 1 output partitions\n",
      "25/03/24 14:20:21 INFO DAGScheduler: Final stage: ResultStage 8 (parquet at NativeMethodAccessorImpl.java:0)\n",
      "25/03/24 14:20:21 INFO DAGScheduler: Parents of final stage: List()\n",
      "25/03/24 14:20:21 INFO DAGScheduler: Missing parents: List()\n",
      "25/03/24 14:20:21 INFO DAGScheduler: Submitting ResultStage 8 (MapPartitionsRDD[21] at parquet at NativeMethodAccessorImpl.java:0), which has no missing parents\n",
      "25/03/24 14:20:21 INFO MemoryStore: Block broadcast_10 stored as values in memory (estimated size 106.2 KiB, free 9.4 GiB)\n",
      "25/03/24 14:20:21 INFO MemoryStore: Block broadcast_10_piece0 stored as bytes in memory (estimated size 38.5 KiB, free 9.4 GiB)\n",
      "25/03/24 14:20:21 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on 192.168.100.210:61924 (size: 38.5 KiB, free: 9.4 GiB)\n",
      "25/03/24 14:20:21 INFO SparkContext: Created broadcast 10 from broadcast at DAGScheduler.scala:1540\n",
      "25/03/24 14:20:21 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 8 (MapPartitionsRDD[21] at parquet at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))\n",
      "25/03/24 14:20:21 INFO TaskSchedulerImpl: Adding task set 8.0 with 1 tasks resource profile 0\n",
      "25/03/24 14:20:21 INFO TaskSetManager: Starting task 0.0 in stage 8.0 (TID 8) (192.168.100.210, executor driver, partition 0, PROCESS_LOCAL, 9155 bytes) \n",
      "25/03/24 14:20:21 INFO Executor: Running task 0.0 in stage 8.0 (TID 8)\n",
      "25/03/24 14:20:21 INFO Executor: Finished task 0.0 in stage 8.0 (TID 8). 2173 bytes result sent to driver\n",
      "25/03/24 14:20:21 INFO TaskSetManager: Finished task 0.0 in stage 8.0 (TID 8) in 6 ms on 192.168.100.210 (executor driver) (1/1)\n",
      "25/03/24 14:20:21 INFO TaskSchedulerImpl: Removed TaskSet 8.0, whose tasks have all completed, from pool \n",
      "25/03/24 14:20:21 INFO DAGScheduler: ResultStage 8 (parquet at NativeMethodAccessorImpl.java:0) finished in 0,012 s\n",
      "25/03/24 14:20:21 INFO DAGScheduler: Job 8 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "25/03/24 14:20:21 INFO TaskSchedulerImpl: Killing all running tasks in stage 8: Stage finished\n",
      "25/03/24 14:20:21 INFO DAGScheduler: Job 8 finished: parquet at NativeMethodAccessorImpl.java:0, took 0,013542 s\n"
     ]
    }
   ],
   "source": [
    "data_0 = spark.read.parquet(os.path.join('..','data', '0-extract.parquet'))\n",
    "data_1 = spark.read.parquet('../data/1-download.parquet')\n",
    "data_3 = spark.read.parquet('../data/3-nucleotids.parquet')\n",
    "data_4 = spark.read.parquet('../data/4-nucleotids.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------------------------------------------------+----------------------+-----------+------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|filename                                                       |patient_key           |patient_id |extract_tumor(filename, data/patient_extracts)                                                                                                        |\n",
      "+---------------------------------------------------------------+----------------------+-----------+------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|patient_000_node_1.tif_tile_44_x0_y166912_score22950.0.png     |patient_000_node_1.tif|patient_000|{[ 28738  32662      0      0 987176], [('Tumour', 2.7407), ('Stroma', 3.1149), ('Inflamatory', 0.0), ('Necrosis', 0.0), ('Others', 94.1444)]}        |\n",
      "|patient_004_node_1.tif_tile_29_x96256_y142336_score25500.0.png |patient_004_node_1.tif|patient_004|{[  1743  70545      0      0 332192], [('Tumour', 0.4309), ('Stroma', 17.4409), ('Inflamatory', 0.0), ('Necrosis', 0.0), ('Others', 82.1282)]}       |\n",
      "|patient_009_node_2.tif_tile_12_x96256_y133120_score25500.0.png |patient_009_node_2.tif|patient_009|{[  3457  16707      0      0 384316], [('Tumour', 0.8547), ('Stroma', 4.1305), ('Inflamatory', 0.0), ('Necrosis', 0.0), ('Others', 95.0148)]}        |\n",
      "|patient_008_node_0.tif_tile_31_x56320_y75776_score24235.5.png  |patient_008_node_0.tif|patient_008|{[     17   43435       0       0 1005124], [('Tumour', 0.0016), ('Stroma', 4.1423), ('Inflamatory', 0.0), ('Necrosis', 0.0), ('Others', 95.8561)]}   |\n",
      "|patient_004_node_2.tif_tile_46_x94208_y47104_score25500.0.png  |patient_004_node_2.tif|patient_004|{[    41 375607      0      0 402592], [('Tumour', 0.0053), ('Stroma', 48.2636), ('Inflamatory', 0.0), ('Necrosis', 0.0), ('Others', 51.7311)]}       |\n",
      "|patient_010_node_3.tif_tile_31_x43008_y38912_score21706.6.png  |patient_010_node_3.tif|patient_010|{[    912      95       0       0 1047569], [('Tumour', 0.087), ('Stroma', 0.0091), ('Inflamatory', 0.0), ('Necrosis', 0.0), ('Others', 99.904)]}     |\n",
      "|patient_004_node_1.tif_tile_129_x92160_y125952_score22950.0.png|patient_004_node_1.tif|patient_004|{[   1328       0       0       0 1047248], [('Tumour', 0.1266), ('Stroma', 0.0), ('Inflamatory', 0.0), ('Necrosis', 0.0), ('Others', 99.8734)]}      |\n",
      "|patient_009_node_2.tif_tile_13_x96256_y134144_score25500.0.png |patient_009_node_2.tif|patient_009|{[  8132   4631      0      0 391717], [('Tumour', 2.0105), ('Stroma', 1.1449), ('Inflamatory', 0.0), ('Necrosis', 0.0), ('Others', 96.8446)]}        |\n",
      "|patient_004_node_2.tif_tile_47_x94208_y48128_score25500.0.png  |patient_004_node_2.tif|patient_004|{[    18 351365      0      0 426857], [('Tumour', 0.0023), ('Stroma', 45.1487), ('Inflamatory', 0.0), ('Necrosis', 0.0), ('Others', 54.849)]}        |\n",
      "|patient_009_node_2.tif_tile_109_x24576_y196608_score23800.0.png|patient_009_node_2.tif|patient_009|{[     0  39310      0      0 593522], [('Tumour', 0.0), ('Stroma', 6.2118), ('Inflamatory', 0.0), ('Necrosis', 0.0), ('Others', 93.7882)]}           |\n",
      "|patient_000_node_1.tif_tile_55_x0_y159744_score22695.0.png     |patient_000_node_1.tif|patient_000|{[   2452       0       0       0 1046124], [('Tumour', 0.2338), ('Stroma', 0.0), ('Inflamatory', 0.0), ('Necrosis', 0.0), ('Others', 99.7662)]}      |\n",
      "|patient_009_node_2.tif_tile_74_x16384_y196608_score25500.0.png |patient_009_node_2.tif|patient_009|{[     0      0      0      0 632832], [('Tumour', 0.0), ('Stroma', 0.0), ('Inflamatory', 0.0), ('Necrosis', 0.0), ('Others', 100.0)]}                |\n",
      "|patient_005_node_0.tif_tile_118_x0_y71680_score22950.0.png     |patient_005_node_0.tif|patient_005|{[ 56016 339454      0   1171 651935], [('Tumour', 5.3421), ('Stroma', 32.3729), ('Inflamatory', 0.0), ('Necrosis', 0.1117), ('Others', 62.1734)]}    |\n",
      "|patient_010_node_3.tif_tile_23_x73728_y82944_score23181.8.png  |patient_010_node_3.tif|patient_010|{[   7013       0       0       0 1041563], [('Tumour', 0.6688), ('Stroma', 0.0), ('Inflamatory', 0.0), ('Necrosis', 0.0), ('Others', 99.3312)]}      |\n",
      "|patient_010_node_4.tif_tile_168_x21504_y93184_score20400.0.png |patient_010_node_4.tif|patient_010|{[     42       0       0       0 1048534], [('Tumour', 0.004), ('Stroma', 0.0), ('Inflamatory', 0.0), ('Necrosis', 0.0), ('Others', 99.996)]}        |\n",
      "|patient_008_node_0.tif_tile_205_x10240_y140288_score16227.3.png|patient_008_node_0.tif|patient_008|{[   7725    7991       0   10760 1022100], [('Tumour', 0.7367), ('Stroma', 0.7621), ('Inflamatory', 0.0), ('Necrosis', 1.0262), ('Others', 97.4751)]}|\n",
      "|patient_000_node_1.tif_tile_53_x0_y145408_score22695.0.png     |patient_000_node_1.tif|patient_000|{[ 29657 191967      0      0 826952], [('Tumour', 2.8283), ('Stroma', 18.3074), ('Inflamatory', 0.0), ('Necrosis', 0.0), ('Others', 78.8643)]}       |\n",
      "|patient_010_node_4.tif_tile_117_x71680_y52224_score23205.0.png |patient_010_node_4.tif|patient_010|{[      0    3959       0       0 1044617], [('Tumour', 0.0), ('Stroma', 0.3776), ('Inflamatory', 0.0), ('Necrosis', 0.0), ('Others', 99.6224)]}      |\n",
      "|patient_008_node_0.tif_tile_59_x91136_y2048_score22971.1.png   |patient_008_node_0.tif|patient_008|{[   4165       0       0       0 1044411], [('Tumour', 0.3972), ('Stroma', 0.0), ('Inflamatory', 0.0), ('Necrosis', 0.0), ('Others', 99.6028)]}      |\n",
      "|patient_004_node_1.tif_tile_47_x96256_y139264_score24990.0.png |patient_004_node_1.tif|patient_004|{[  1175 111391      0      0 291914], [('Tumour', 0.2905), ('Stroma', 27.5393), ('Inflamatory', 0.0), ('Necrosis', 0.0), ('Others', 72.1702)]}       |\n",
      "+---------------------------------------------------------------+----------------------+-----------+------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/03/24 14:22:38 INFO FileSourceStrategy: Pushed Filters: \n",
      "25/03/24 14:22:38 INFO FileSourceStrategy: Post-Scan Filters: \n",
      "25/03/24 14:22:38 INFO CodeGenerator: Code generated in 11.724084 ms\n",
      "25/03/24 14:22:38 INFO MemoryStore: Block broadcast_21 stored as values in memory (estimated size 220.0 KiB, free 9.4 GiB)\n",
      "25/03/24 14:22:38 INFO MemoryStore: Block broadcast_21_piece0 stored as bytes in memory (estimated size 36.7 KiB, free 9.4 GiB)\n",
      "25/03/24 14:22:38 INFO BlockManagerInfo: Added broadcast_21_piece0 in memory on 192.168.100.210:61924 (size: 36.7 KiB, free: 9.4 GiB)\n",
      "25/03/24 14:22:38 INFO SparkContext: Created broadcast 21 from showString at NativeMethodAccessorImpl.java:0\n",
      "25/03/24 14:22:38 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.\n",
      "25/03/24 14:22:38 INFO SparkContext: Starting job: showString at NativeMethodAccessorImpl.java:0\n",
      "25/03/24 14:22:38 INFO DAGScheduler: Got job 14 (showString at NativeMethodAccessorImpl.java:0) with 1 output partitions\n",
      "25/03/24 14:22:38 INFO DAGScheduler: Final stage: ResultStage 14 (showString at NativeMethodAccessorImpl.java:0)\n",
      "25/03/24 14:22:38 INFO DAGScheduler: Parents of final stage: List()\n",
      "25/03/24 14:22:38 INFO DAGScheduler: Missing parents: List()\n",
      "25/03/24 14:22:38 INFO DAGScheduler: Submitting ResultStage 14 (MapPartitionsRDD[45] at showString at NativeMethodAccessorImpl.java:0), which has no missing parents\n",
      "25/03/24 14:22:38 INFO MemoryStore: Block broadcast_22 stored as values in memory (estimated size 16.1 KiB, free 9.4 GiB)\n",
      "25/03/24 14:22:38 INFO MemoryStore: Block broadcast_22_piece0 stored as bytes in memory (estimated size 6.7 KiB, free 9.4 GiB)\n",
      "25/03/24 14:22:38 INFO BlockManagerInfo: Added broadcast_22_piece0 in memory on 192.168.100.210:61924 (size: 6.7 KiB, free: 9.4 GiB)\n",
      "25/03/24 14:22:38 INFO SparkContext: Created broadcast 22 from broadcast at DAGScheduler.scala:1540\n",
      "25/03/24 14:22:38 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 14 (MapPartitionsRDD[45] at showString at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))\n",
      "25/03/24 14:22:38 INFO TaskSchedulerImpl: Adding task set 14.0 with 1 tasks resource profile 0\n",
      "25/03/24 14:22:38 INFO TaskSetManager: Starting task 0.0 in stage 14.0 (TID 26) (192.168.100.210, executor driver, partition 0, PROCESS_LOCAL, 9515 bytes) \n",
      "25/03/24 14:22:38 INFO Executor: Running task 0.0 in stage 14.0 (TID 26)\n",
      "25/03/24 14:22:38 INFO FileScanRDD: Reading File path: file:///Users/illorens/Projects/source/Universidad/viu-MU-BD-and-DS-Image-Pathology/data/4-nucleotids.parquet/part-00000-15b33fbf-cd58-40de-88ae-ffb2f621a3be-c000.snappy.parquet, range: 0-16464, partition values: [empty row]\n",
      "25/03/24 14:22:38 INFO Executor: Finished task 0.0 in stage 14.0 (TID 26). 3992 bytes result sent to driver\n",
      "25/03/24 14:22:38 INFO TaskSetManager: Finished task 0.0 in stage 14.0 (TID 26) in 7 ms on 192.168.100.210 (executor driver) (1/1)\n",
      "25/03/24 14:22:38 INFO TaskSchedulerImpl: Removed TaskSet 14.0, whose tasks have all completed, from pool \n",
      "25/03/24 14:22:38 INFO DAGScheduler: ResultStage 14 (showString at NativeMethodAccessorImpl.java:0) finished in 0,010 s\n",
      "25/03/24 14:22:38 INFO DAGScheduler: Job 14 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "25/03/24 14:22:38 INFO TaskSchedulerImpl: Killing all running tasks in stage 14: Stage finished\n",
      "25/03/24 14:22:38 INFO DAGScheduler: Job 14 finished: showString at NativeMethodAccessorImpl.java:0, took 0,011784 s\n"
     ]
    }
   ],
   "source": [
    "data_4.show(truncate=False)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
